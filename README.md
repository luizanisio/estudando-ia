# estudando-ia

## Consolidando algumas dicas e estudos de IA e ML

Resolvi consolidar alguns resultados de estudos realizados com o uso de elasticsearch e python e ferramentas/framework de IA/ML para facilitar o trabalho de quem est√° iniciando nessa √°rea. Esse n√£o √© um trabalho acad√™mico e n√£o visa esgotar todo o assunto, √© um espa√ßo de compartilhamento de conhecimento adquirido. <br>
Divirta-se!<br>
Coloquei o ano na refer√™ncia de alguns conte√∫dos para refletir a linha de tempo.

### üí° Minha pequena reflex√£o sobre aprendizado de m√°quina vs humano: 
 - üñ•Ô∏è A m√°quina identifica padr√µes para responder a uma nova informa√ß√£o com dados usados no treino e sugere respostas prov√°veis com base nos dados selecionados por `humanos` para esse treinamento. Sua capacidade de aprendizado √© limitada aos padr√µes identificados nos dados selecionados para o treino, e que precisam ser atualizados de tempos em tempos com dados de qualidade, exigindo esfor√ßo humano para isso. √â uma √≥tima op√ß√£o para tarefas simples e repetitivas. <i>A m√°quina n√£o se cansa de fazer a mesma coisa da mesma forma indefinidamente.</i>
 - :bust_in_silhouette: Humanos identificam padr√µes para responder a uma nova experi√™ncia ao comparar as informa√ß√µes dispon√≠veis com uma rica e complexa bagagem  `cultural`, `pessoal` e `profissional` atrav√©s da sua estrutura `filogen√©tica`, podendo buscar e interpretar novas fontes de informa√ß√£o e acrescent√°-las quase em tempo real √† sua experi√™ncia de vida, permitindo sugerir respostas mais adequadas aos novos contextos. <i>Sua capacidade de aprendizado √© praticamente ilimitada</i>, o limite √© o tempo e o desgaste biol√≥gico no processo de aprendizado. 
 - :point_right: O objetivo dos projetos de IA √© liberar humanos de tarefas repetitivas, simples e que exigem pouca intelig√™ncia na sua execu√ß√£o, para que esses humanos possa realizar melhor tarefas realmente inteligentes.
 > :warning: √â sempre bom lembrar que a m√°quina n√£o aprende como o ser humano aprende, ela n√£o vai absorver conhecimento dos dados, textos ou imagens apresentados no treinamento e nem vai interpret√°-los com base na sua bagagem filogen√©tica, ontogen√©tica e cultura. O que vemos como resultado de v√°rios c√°lculos assemelha-se em alguns momentos ao que vemos como resultado de comportamentos humanos encobertos (processos intelectuais, pensamentos, interpreta√ß√µes, etc), o que faz parecer que existem processos humanos acontecendo tamb√©m dentro da m√°quina. Colocando uma m√°quina em um "corpo human√≥ide", logo surge a ideia que as m√°quinas est√£o muito pr√≥ximas de se tornarem humanas. :no_entry_sign: 
 
## O que voc√™ pode encontrar por aqui: 
Alguns t√≥picos abordados aqui com exemplos funcionais e dicas de como evolu√≠-los e us√°-los no dia-a-dia. Est√£o mais pr√≥ximos de receitas do tipo pegar, analisar, adaptar e usar. Sempre que poss√≠vel estarei incluindo novos estudos e c√≥digos funcionais.

- `2021` <b> Elasticsearch f√°cil e preciso</b> como transformar o uso de operadores simples e de proximidade de termos em consultas robustas do ElasticSearch sem que o usu√°rio precise conhecer a sintaxe do ElasticSearch, veja aqui: [PesquisaElasticFacil](https://github.com/luizanisio/PesquisaElasticFacil) , incluindo dicas de queries mais robustas do ElasticSearch para proximidade de termos, veja aqui: [ElasticQueries](https://github.com/luizanisio/PesquisaElasticFacil/blob/main/ElasticQueries.md)

- `2021` <b> Doc2Vec criando um modelo de forma f√°cil</b> um componente que simplifica a cria√ß√£o de um vocab para treinamento do Doc2Vec e a curadoria do modelo em treinamento usando o framework [`Gensim 4.0.1`](https://radimrehurek.com/gensim/), veja aqui: [Doc2VecFacil](https://github.com/luizanisio/Doc2VecFacil), com alguns componentes para criar e fazer curadoria de [`ngramas`](https://github.com/luizanisio/Doc2VecFacil/blob/main/readme_ngramas.md), transforma√ß√£o de termos durante a tokeniza√ß√£o, dentre outros. 

- `2019` <b> Elasticsearch</b> utilizando o elasticsearch na classifica√ß√£o de documentos, identifica√ß√£o de fluxos de trabalho e textos relacionados (dicas, faq, etc). Uma forma simples, sustent√°vel e r√°pida de implementar um classificador com bons resultados, sem a necessidade de gera√ß√£o e atualiza√ß√£o de modelos. [Classificador Elastic](https://github.com/luizanisio/classificador_elastic). Se combinado com vetores usando o [Doc2VecFacil](https://github.com/luizanisio/Doc2VecFacil), pode trazer resultados ainda mais precisos.

- `2019` <b> Elasticsearch + sklearn (compara√ß√£o e resumo de documentos)</b> utilizando o elasticsearch para comparar dois ou mais documentos, e para sumarizar documentos encontrando as senten√ßas relevantes do mesmo, sem precisar guardar os documentos no elastic. Inclu√≠ tamb√©m um exemplo de compara√ß√£o de documentos com shingles, stop words, tfidf etc em <b>3 linhas</b> usando o <b>Sklearn</b>. A principal diferen√ßa √© que o sklearn usa os pr√≥prios documentos para a identifica√ß√£o dos termos relevantes (<i>neste exemplo</i>), e com o elastic usamos os algoritmos do elastic para calcular os termos relevantes em seu conjunto de documentos e usando os analisadores que criarmos (com seu stemmer, stopword, sin√¥nimos etc). Da mesma forma podemos calcular os pesos de cada senten√ßa de um documento e criar um algoritmo de resumo por extra√ß√£o. [Comparador Elastic](https://github.com/luizanisio/comparador_elastic) 
 
- `2019` <b>Em elabora√ß√£o</b> <i>(estou organizando os c√≥digos)</i>: algumas dicas e exemplos pr√°ticos de treinamento em redes neurais utilizando a biblioteca Spacy (criando modelos de extra√ß√£o de entidades, depend√™ncia entre elas e classifica√ß√£o de textos). O Spacy √© uma ferramenta poderosa e relativamente simples de usar. [Spacy Treino](https://github.com/luizanisio/spacy_treino) 
 
- `2019` <b>Em breve</b>: esse c√≥digo ainda n√£o est√° completo, mas estou elaborando um workflow de treinamento para o Spacy, permitindo a gera√ß√£o, atualiza√ß√£o e deploy de modelos gerados no Spacy. A ideia √© ter uma interface de marca√ß√£o de entidades, depend√™ncias e classifica√ß√µes, tendo um motor atualizando os modelos e permitindo testes e deploy dos mesmos de forma automatizada. Se eu achar um antes de fazer, vou postar aqui.
 
- `2019` Criando vetores de palavras (<b>word2vec</b>) com <b>Gensim</b> para tratar similaridade textual em dom√≠nios espec√≠ficos com o uso do <b>Spacy</b>. Incluindo a visualiza√ß√£o do universo de termos usando o <b>tensorboard</b>. Ainda √© poss√≠vel gerar um dicion√°rio de sin√¥nimos para ser usado no elasticsearch. [Word2Vec com Spacy](https://github.com/luizanisio/word2vec_spacy) 
 
## Links interessantes:
`2021` 
- NLP com redes neurais: Spacy: https://spacy.io/ - https://github.com/explosion/spaCy
- sklearn: http://scikit-learn.org
- Framework Gensim (vetoriza√ß√£o): https://radimrehurek.com/gensim/
- Cadeia de Markov: https://en.wikipedia.org/wiki/Markov_chain
- Redes Neurais, como funsionam? [Prof Vinicius Carid√° - parte 1](https://www.youtube.com/watch?v=EtnBTb0MKqs), [Prof Vinicius Carid√° - parte 2](https://www.youtube.com/watch?v=kgReLNhXsOI) e [Prof Vinicius Carid√° - parte 3](https://www.youtube.com/watch?v=UHR2LIw4KMA)
- SVM, como funciona? [Prof Vinicius Carid√°](https://www.youtube.com/watch?v=E3DRhPymT6Y)
- Elasticsearch: https://www.elastic.co/
- MemSQL / SingleStore (banco de dados vetorial NewSQL): https://www.singlestore.com/
- IDE python: [PyCharm](https://www.jetbrains.com/pycharm/), [VSCode](https://visualstudio.microsoft.com/pt-br/vs/community/)
- Cliente git: https://www.gitkraken.com

## Ferramentas 
`2020` 
- Knime (ferramenta para an√°lise de dados e ML): https://www.knime.com/
- Python na nuvem com o Google Colaboratory: https://colab.research.google.com/
- Weka: https://en.wikipedia.org/wiki/Weka_(machine_learning)

### Docker:
`2019` 
  - conteinerizar os servi√ßos python: https://hub.docker.com/_/python/
  - conteinerizar o elasticsearch e kibana: https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html

## Cursos gratuitos b√°sicos:
`2021` 
- <b>Curso Intelig√™ncia Artificial Fundamentos</b>: https://www.datascienceacademy.com.br/course?courseid=inteligencia-artificial-fundamentos
- <b>Python Fundamentos para An√°lise de Dados</b>: https://www.datascienceacademy.com.br/course?courseid=python-fundamentos
- <b>Bootcamp for KNIME Analytics Platform</b> (teoria e ferramenta) https://www.udemy.com/course/knime-bootcamp/
- <b>Advanced NLP with spaCy</b>: [spacy2](https://course.spacy.io/) e [spacy3](https://spacy.io/usage/v3/)
- <b>Introdu√ß√£o IA </b>: https://www.datascienceacademy.com.br/course?courseid=inteligencia-artificial-fundamentos
- <b>Python completo</b>: https://www.datascienceacademy.com.br/course?courseid=python-fundamentos
- <b>Introdu√ß√£o √† ci√™ncia de dados</b>: https://www.datascienceacademy.com.br/course?courseid=introduo--cincia-de-dados
- <b>Aprendizagem profunda</b>: https://www.coursera.org/specializations/deep-learning
- <b>Kmine</b>: https://www.udemy.com/course/datascience-knime/learn/lecture/13678654#overview
- <b>Weka</b>: https://www.udemy.com/course/machine-learning-e-deep-learning/learn/lecture/10409622?start=0#overview
- <b>Deeplizard - aprendizagem profunda com tensorflow</b>: https://deeplizard.com/

## Cursos acess√≠veis b√°sicos:
`2021` 
- <b>Curso Machine Learning para todos</b> (com Weka): https://www.udemy.com/share/101F6mAkUccFlbRHo=/
- <b>End to End Data Science Practicum with Knime</b> (teoria e ferramenta) https://www.udemy.com/course/datascience-knime/learn/

## Cursos gratuitos mais espec√≠ficos/avan√ßados:
`2019` 
- <b>Aprendizagem Autom√°tica</b> (Stanford University):  https://www.coursera.org/learn/machine-learning/home/welcome
- <b>MemSQL developer</b>: https://training.memsql.com/courses/memsql-65-developer-sp-training
<hr>

## Agradecimentos
- Estou consolidando aqui estudos na √°rea de IA/ML e cada c√≥digo ou exemplo tem a participa√ß√£o direta ou indireta dos meus colegas de trabalho Rodrigo L√≥pez, Thiago Gomes e Amilar Martins, que me apresentaram ao mundo IA, e Rhodie Ferreira e Virg√≠nia Martins que n√£o se cansam de estudar e contribuir com todos a sua volta, tanto no √¢mbito profissional como pessoal. E de grandes profissionais como o Ricardo Bernardes, Jo√£o Bosco e Osmar que contribuem diariamente para o meu aprendizado em c√≥digos e solu√ß√µes diversas. E o meu padrinho Prof. Dr. Luciano Vieira Lima que desde sempre me d√° dicas importantes em todas as √°reas t√©cnicas ou n√£o.
